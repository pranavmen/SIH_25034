# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14H-Rpo7GlNNrUtc_pmNMYUEySDY_k_iq
"""

# You will need sentence-transformers
# pip install -U sentence-transformers

import csv
from sentence_transformers import SentenceTransformer, util
import torch

# --- HELPER FUNCTIONS ---
def create_internship_text(internship):
    """Creates a more natural, descriptive sentence from internship data."""
    title = internship.get('Title', 'an internship role')
    skills = internship.get('Skills', 'various skills')
    return f"Seeking an intern for a {title} position. The ideal candidate should have experience in skills such as {skills}."

def calculate_keyword_score(student_skills, internship_skills):
    """Calculates a score based on the overlap of skills (Jaccard Similarity)."""
    student_set = set([skill.strip().lower() for skill in student_skills.split(',')])
    internship_set = set([skill.strip().lower() for skill in internship_skills.split(',')])
    intersection = student_set.intersection(internship_set)
    union = student_set.union(internship_set)
    return 0.0 if not union else len(intersection) / len(union)

# --- CORE LOGIC ---
def find_recommendations(student_profile, all_internships, model):
    """Finds and ranks recommendations by calculating embeddings on the fly."""
    print(f"\nüîé Finding recommendations for a student in '{student_profile['location_preference']}'...")

    # Step 1: Filter internships by location
    filtered_internships = [
        internship for internship in all_internships
        if internship['Location'].lower() == student_profile['location_preference'].lower()
    ]
    if not filtered_internships:
        return [], 0

    # Step 2: Prepare text (no special prefixes needed for this model)
    student_text = f"A student with key skills in: {student_profile['skills']}."
    internship_texts = [create_internship_text(internship) for internship in filtered_internships]

    # Step 3: Generate embeddings for both student and internships in real-time
    print(f"üß† Generating embeddings for {len(filtered_internships)} internships...")
    student_embedding = model.encode(student_text, convert_to_tensor=True)
    internship_embeddings = model.encode(internship_texts, convert_to_tensor=True, show_progress_bar=True)

    # Step 4: Calculate similarity
    semantic_scores = util.cos_sim(student_embedding, internship_embeddings)

    # Step 5: Combine scores and rank
    recommendations = []
    for i, internship in enumerate(filtered_internships):
        sem_score = semantic_scores[0][i].item()
        key_score = calculate_keyword_score(student_profile['skills'], internship.get('Skills', ''))
        final_score = (0.6 * sem_score) + (0.4 * key_score)
        recommendations.append({'final_score': final_score, 'internship': internship})

    sorted_recommendations = sorted(recommendations, key=lambda x: x['final_score'], reverse=True)
    return sorted_recommendations, len(filtered_internships)

# --- MAIN EXECUTION BLOCK ---
if __name__ == "__main__":
    # You may need to adjust this threshold after observing the new scores
    MINIMUM_SCORE_THRESHOLD = 0.50
    FALLBACK_COUNT = 3 # Number of recommendations to show if no good matches are found

    print("Loading model and data...")
    # Switched to the new model name
    MODEL_NAME = 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'
    model = SentenceTransformer(MODEL_NAME)

    all_internships = []
    with open('internships.csv', mode='r', encoding='utf-8') as csvfile:
        reader = csv.DictReader(csvfile)
        for row in reader:
            all_internships.append(row)

    print("‚úÖ Model and data loaded.")

    student = {
        'skills': 'Python, Machine Learning, PyTorch, SQL, data analysis, Pandas',
        'location_preference': 'Work From Home'
    }

    all_recommendations, jobs_found_in_location = find_recommendations(student, all_internships, model)

    # First, try to get high-quality matches
    good_recommendations = [rec for rec in all_recommendations if rec['final_score'] >= MINIMUM_SCORE_THRESHOLD]

    print("\n--- üèÜ Top Internship Recommendations ---")
    if good_recommendations:
        print(f"Displaying top matches above a score of {MINIMUM_SCORE_THRESHOLD}...")
        for rec in good_recommendations[:5]:
            details = rec['internship']
            print(f"\nFinal Score: {rec['final_score']:.4f}")
            print(f"  Title: {details['Title']}")
            print(f"  Skills: {details['Skills']}")
            print(f"  Location: {details['Location']}")

    # Fallback logic
    elif jobs_found_in_location > 0:
        print(f"\n‚ÑπÔ∏è No ideal matches were found. Here are the {FALLBACK_COUNT} closest options in {student['location_preference']}:")
        for rec in all_recommendations[:FALLBACK_COUNT]:
            details = rec['internship']
            print(f"\nScore: {rec['final_score']:.4f} (Closest Match)")
            print(f"  Title: {details['Title']}")
            print(f"  Skills: {details['Skills']}")
            print(f"  Location: {details['Location']}")

    else:
        print(f"\n‚ÑπÔ∏è No jobs were found for your preferred location: {student['location_preference']}.")